\documentclass[12pt]{article}

\usepackage{mathnotes}
\pgfplotsset{compat=1.18}
% Title Information
\title{\Huge  \color{maincolor} Notas de Cálculo Numérico}
\author{Ramiro Dibur}
\date{}

% Document

\begin{document}

\pagenumbering{gobble}
\vspace*{\fill}
\begin{center}
    \vspace*{\stretch{1}}
    {\Huge \color{maincolor} Notas de Cálculo Numérico} \\[1em]
    {\large Ramiro Dibur}
    \vspace*{\stretch{2}}
\end{center}
\vspace*{\fill}
\newpage
\pagenumbering{arabic}
\newpage
\tableofcontents
\newpage

\section{Aritmética de punto flotante}

En esta sección se introduce cómo se representan los números en una computadora, los errores asociados a estas representaciones, y cómo estos errores pueden propagarse en los cálculos. Además, se presentan ejemplos de problemas mal condicionados y se discute el concepto de estabilidad numérica.

\subsection{Números de máquina}

Un número real $x \neq 0$ puede representarse en una base $b \in \mathbb{N}$, $b \ge 2$, mediante una expansión en serie:
$$
    x = \pm \left( d_k b^k + d_{k-1} b^{k-1} + \dots + d_0 b^0 + d_{-1} b^{-1} + d_{-2} b^{-2} + \dots \right)
$$
donde los dígitos $d_i$ satisfacen $0 \le d_i \le b-1$. Esta representación es única si se excluyen las expansiones infinitas que terminan en una secuencia de $b-1$.

Sin embargo, como en las computadoras tenemos espacio finito, nece

\begin{definition}
    Un número de máquina (o número de punto flotante) $x$ en base $b$ se representa generalmente en forma normalizada como
    $$
        x = \pm (0.d_1 d_2 \dots d_m)_b \times b^e
    $$
    donde $d_1 d_2 \dots d_m$ es la mantisa y $e$ el exponente.
\end{definition}

Dado un número real $x$, si no es un número de máquina, debe ser aproximado por uno. El proceso de aproximación se llama redondeo. Dos estrategias comunes son:

\begin{itemize}
    \item \textbf{Redondeo al más cercano}: Se elige el número de máquina más cercano a $x$.
    \item \textbf{Truncamiento (o redondeo hacia cero)}: Se elige el número de máquina más cercano a $x$ en dirección hacia cero.
\end{itemize}

Es posible que el resultado de una operación no pueda representarse exactamente debido a las limitaciones en la precisión de los números de máquina. Esto puede dar lugar a dos tipos principales de errores:

\begin{itemize}
    \item \textbf{Overflow:} Ocurre cuando el resultado de una operación excede en magnitud el número de máquina más grande que se puede representar. Esto puede llevar a resultados infinitos o errores en los cálculos.
    \item \textbf{Underflow:} Ocurre cuando el resultado de una operación es menor en magnitud que el número de máquina positivo más pequeño que se puede representar (sin ser cero). En este caso, el resultado puede aproximarse a cero, lo que puede introducir errores de redondeo.
\end{itemize}

\subsection{Error absoluto y relativo}

\begin{definition}
    Si $fl(x)$ es la representación de máquina de $x$, el error absoluto se define como 
    $$|x - fl(x)|,$$
    y el error relativo como 
    $$\frac{|x - fl(x)|}{|x|}.$$
\end{definition}

Para el redondeo al más cercano, el error absoluto está acotado por
$$|x - fl(x)| \leq \frac{1}{2} b^{e-m},$$ donde $e$ es el exponente tal que $b^{e-1} \le |x| < b^e$. El error relativo está acotado por
$$
    \left| \frac{x - fl(x)}{x} \right| \le \frac{1}{2} b^{1-m}.
$$

\subsection{Épsilon de Máquina}

\begin{definition}
    El \emph{épsilon de máquina}, denotado por $\varepsilon$, es la cota superior del error relativo cometido al representar un número real mediante un número de máquina utilizando el redondeo al más cercano.
    $$
        \varepsilon = \frac{1}{2} b^{1-m}.
    $$
\end{definition}

\begin{remark}
    En \texttt{python}, con variables del tipo \texttt{float}, el valor de $\varepsilon$ se puede obtener utilizando el módulo \texttt{sys}:
    \begin{lstlisting}[language=iPython]
import numpy as np
np.finfo(float).eps\end{lstlisting}
    Este valor representa la diferencia más pequeña entre $1.0$ y el siguiente número representable mayor que $1.0$ en la aritmética de punto flotante de la máquina.
\end{remark}

En general, cuando realizamos operaciones, los errores de la máquina se acumulan. Veamos qué pasa cuando sumamos dos números cualesquiera en la máquina.

Sean $x$ e $y$ números con el mismo signo tales que sus errores relativos son $\mu_x$ y $\mu_y$, respectivamente. Notemos que $|\mu_x|, |\mu_y| \leq \varepsilon$. Sea $\mu_z$ el error relativo de la suma. Entonces,
\begin{align*}
    x \oplus y &= fl(fl(x) + fl(y)) \\
    &= (fl(x) + fl(y))(1 + \mu_z) \\
    \implies \left| x \oplus y - (x+y) \right| &\leq (x + y) 2 \varepsilon + O(\varepsilon^{2}).
\end{align*}
Y entonces nos queda
$$
    \frac{\left| x \oplus y - (x + y) \right| }{\left| x + y \right| } \lesssim 2\varepsilon.
$$

\section{Aproximación de EDOs}

Consideramos las ecuaciones diferenciales ordinarias de orden $1$. El problema de valores iniciales (PVI) consta en hallar $x: (a, b) \to \mathbb{R}$ tal que 
$$
    \begin{cases}
        x'(t) = f(t, x) \\
        x(t_0) = x_0.
    \end{cases}
$$
Las hipótesis más usuales son que 
\begin{itemize}
    \item $f$ continua.
    \item $f$ Lipschitz en la variable $x$.
\end{itemize}
Dadas estas hipótesis, existe una única solución del problema de valores iniciales. Además, son necesarias para los métodos numéricos, ya que sino no hay forma de corroborar qué solución está dando un método.

\subsection{Método de Euler}

\begin{custombox}[Método de Euler]
    Dado el problema de valores iniciales
    $$
    \begin{cases}
        x'(t) = f(t, x) \\
        x(t_0) = x_0,
    \end{cases}
    $$
    queremos aproximar $x(T)$ para $T > t_0$. Tomamos $N \in \mathbb{N}$ y $h = \frac{T - t_0}{N}$. Entonces,
    \begin{itemize}
        \item $t_i = t_0 + h \cdot i$ para $0 \leq i \leq N$.
        \item $x_{i+1} = x_i + h \cdot f(x_i, t_i)$
    \end{itemize}

\end{custombox}



\end{document}